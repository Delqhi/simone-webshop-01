# =============================================================================
# PROMETHEUS ALERT RULES - SIN-SOLVER INFRASTRUCTURE MONITORING
# =============================================================================

groups:
  # ===========================================================================
  # INFRASTRUCTURE ALERTS - Critical services
  # ===========================================================================
  - name: infrastructure_alerts
    interval: 30s
    rules:
      # Service Health Checks
      - alert: ServiceDown
        expr: up{job=~"agent.*|room.*|solver.*"} == 0
        for: 2m
        labels:
          severity: critical
          component: infrastructure
        annotations:
          summary: "{{ $labels.job }} is DOWN"
          description: "Service {{ $labels.job }} ({{ $labels.instance }}) has been down for more than 2 minutes"
          runbook: "Check service logs: docker logs {{ $labels.instance }}"

      - alert: ServiceUnhealthy
        expr: container_status_running{name=~".*-.*-.*"} == 0
        for: 3m
        labels:
          severity: warning
          component: infrastructure
        annotations:
          summary: "{{ $labels.name }} is not running"
          description: "Container {{ $labels.name }} is not in running state"

      # Database Alerts
      - alert: PostgresDatabaseDown
        expr: up{job="room-03-postgres"} == 0
        for: 1m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "PostgreSQL Database is DOWN"
          description: "PostgreSQL primary database (room-03-archiv-postgres) is unreachable"
          runbook: "docker logs room-03-archiv-postgres"

      - alert: PostgresConnectionLimitWarning
        expr: pg_stat_activity_count > 180
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "PostgreSQL connections approaching limit"
          description: "Active PostgreSQL connections: {{ $value }} / 200"

      # Redis Cache Alerts
      - alert: RedisDown
        expr: up{job="room-04-redis"} == 0
        for: 1m
        labels:
          severity: critical
          component: cache
        annotations:
          summary: "Redis Cache is DOWN"
          description: "Redis cache (room-04-memory-redis) is unreachable"
          runbook: "docker logs room-04-memory-redis"

  # ===========================================================================
  # RESOURCE ALERTS - CPU, Memory, Disk
  # ===========================================================================
  - name: resource_alerts
    interval: 30s
    rules:
      # CPU Usage Alerts
      - alert: HighCPUUsage
        expr: (rate(container_cpu_usage_seconds_total[5m]) * 100) > 80
        for: 5m
        labels:
          severity: warning
          component: resources
        annotations:
          summary: "High CPU usage: {{ $labels.name }}"
          description: "Container {{ $labels.name }} CPU usage is {{ $value | humanizePercentage }}"

      - alert: CriticalCPUUsage
        expr: (rate(container_cpu_usage_seconds_total[5m]) * 100) > 95
        for: 2m
        labels:
          severity: critical
          component: resources
        annotations:
          summary: "CRITICAL CPU usage: {{ $labels.name }}"
          description: "Container {{ $labels.name }} CPU usage is {{ $value | humanizePercentage }}"
          runbook: "Scale horizontally or optimize code. Check: docker stats {{ $labels.name }}"

      # Memory Usage Alerts
      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_memory_max_bytes) > 0.80
        for: 5m
        labels:
          severity: warning
          component: resources
        annotations:
          summary: "High memory usage: {{ $labels.name }}"
          description: "Container {{ $labels.name }} using {{ humanize $value }}% of limit"

      - alert: CriticalMemoryUsage
        expr: (container_memory_usage_bytes / container_memory_max_bytes) > 0.95
        for: 2m
        labels:
          severity: critical
          component: resources
        annotations:
          summary: "CRITICAL memory usage: {{ $labels.name }}"
          description: "Container {{ $labels.name }} using {{ humanize $value }}% of limit - OOM likely!"
          runbook: "Increase memory limit or optimize memory usage. Check: docker stats {{ $labels.name }}"

      # Host-level Disk Usage
      - alert: HighDiskUsage
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) < 0.20
        for: 5m
        labels:
          severity: warning
          component: resources
        annotations:
          summary: "High disk usage on host"
          description: "Only {{ $value | humanizePercentage }} disk space remaining"

      - alert: CriticalDiskUsage
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) < 0.10
        for: 2m
        labels:
          severity: critical
          component: resources
        annotations:
          summary: "CRITICAL disk usage on host"
          description: "Only {{ $value | humanizePercentage }} disk space remaining - risk of full disk"
          runbook: "Clean up logs and volumes: docker system prune"

  # ===========================================================================
  # APPLICATION ALERTS - Business logic & errors
  # ===========================================================================
  - name: application_alerts
    interval: 30s
    rules:
      # n8n Workflow Failures
      - alert: N8nWorkflowFailures
        expr: increase(n8n_workflow_execution_failed_total[5m]) > 0
        for: 5m
        labels:
          severity: warning
          component: orchestration
        annotations:
          summary: "n8n workflow failures detected"
          description: "{{ $value }} workflow failures in last 5 minutes"
          runbook: "Check n8n dashboard: https://n8n.delqhi.com"

      # High Error Rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(container_network_receive_errors_total[5m])) by (name) +
            sum(rate(container_network_transmit_errors_total[5m])) by (name)
          ) > 10
        for: 5m
        labels:
          severity: warning
          component: networking
        annotations:
          summary: "High network error rate: {{ $labels.name }}"
          description: "Network errors rate: {{ $value | humanize }}/s"

  # ===========================================================================
  # AVAILABILITY ALERTS - Uptime and SLA
  # ===========================================================================
  - name: availability_alerts
    interval: 30s
    rules:
      # Service Restart Frequency
      - alert: FrequentServiceRestarts
        expr: increase(container_last_seen[5m]) > 2
        for: 10m
        labels:
          severity: warning
          component: reliability
        annotations:
          summary: "Service restarting frequently: {{ $labels.name }}"
          description: "{{ $labels.name }} has restarted {{ $value }} times in 5 minutes"
          runbook: "Check service logs for crash reasons: docker logs {{ $labels.name }}"

      # Low Uptime
      - alert: ServiceHighRestartCount
        expr: container_last_seen > 10
        for: 5m
        labels:
          severity: critical
          component: reliability
        annotations:
          summary: "CRITICAL: Service restarting excessively: {{ $labels.name }}"
          description: "{{ $labels.name }} has restarted {{ $value }} times - check for configuration errors"

