# =============================================================================
# ALERTMANAGER CONFIGURATION - Alert routing & notification
# =============================================================================

global:
  resolve_timeout: 5m
  slack_api_url: '${SLACK_WEBHOOK_URL:-http://localhost:5000}'
  smtp_smarthost: '${SMTP_HOST:-smtp.gmail.com}:587'
  smtp_auth_username: '${SMTP_USER:-noreply@delqhi.com}'
  smtp_auth_password: '${SMTP_PASSWORD:-}'
  smtp_from: '${SMTP_FROM:-alerts@delqhi.com}'

# Templates for notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Alert routing tree
route:
  # Default receiver for all alerts
  receiver: 'default-receiver'
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h

  # Critical alerts - immediate notification
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      continue: true
      group_wait: 0s
      repeat_interval: 1h

    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 30s
      repeat_interval: 4h

    - match:
        component: database
      receiver: 'database-alerts'
      continue: true

    - match:
        component: resources
      receiver: 'resource-alerts'
      continue: true

# Alert receivers (notification destinations)
receivers:
  # Default receiver - all alerts
  - name: 'default-receiver'
    slack_configs:
      - channel: '#alerts'
        title: 'Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'

  # Critical severity alerts
  - name: 'critical-alerts'
    slack_configs:
      - channel: '#critical-alerts'
        title: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}\nRunbook: {{ .Annotations.runbook }}{{ end }}'
        send_resolved: true
        color: 'danger'
    email_configs:
      - to: '${ALERT_EMAIL:-admin@delqhi.com}'
        headers:
          Subject: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'

  # Warning severity alerts
  - name: 'warning-alerts'
    slack_configs:
      - channel: '#warnings'
        title: '‚ö†Ô∏è WARNING: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: false
        color: 'warning'

  # Database-specific alerts
  - name: 'database-alerts'
    slack_configs:
      - channel: '#database'
        title: 'üóÑÔ∏è Database Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}\nInstance: {{ .Labels.instance }}{{ end }}'
        send_resolved: true
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'

  # Resource usage alerts
  - name: 'resource-alerts'
    slack_configs:
      - channel: '#infrastructure'
        title: 'üìä Resource Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}Container: {{ .Labels.name }}\n{{ .Annotations.description }}{{ end }}'
        send_resolved: true

# Inhibition rules - suppress alerts under certain conditions
inhibit_rules:
  # Don't alert on high CPU if service is already down
  - source_match:
      severity: 'critical'
      alertname: 'ServiceDown'
    target_match_re:
      alertname: 'HighCPUUsage|HighMemoryUsage'
    equal: ['instance']

  # Don't alert on memory usage if OOM has occurred
  - source_match:
      severity: 'critical'
      alertname: 'CriticalMemoryUsage'
    target_match:
      severity: 'warning'
      alertname: 'HighMemoryUsage'
    equal: ['instance']

  # Suppress warnings if critical alert exists
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

